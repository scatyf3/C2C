2025-12-20 10:44:39,898 - datasets - DEBUG - PyTorch version 2.6.0 available.
2025-12-20 10:44:40,172 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-12-20 10:44:40,230 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/nics-efc/C2C_Fuser/revision/main HTTP/1.1" 200 30238
Fetching 59 files:   0%|          | 0/59 [00:00<?, ?it/s]Fetching 59 files: 100%|██████████| 59/59 [00:00<00:00, 6614.74it/s]
2025-12-20 10:44:40,249 - script.playground.inference_example - INFO - Loading Rosetta model with SLM: Qwen/Qwen3-0.6B, LLM: Qwen/Qwen2.5-0.5B-Instruct, checkpoints from: /scratch/yf3005/.cache/huggingface/hub/models--nics-efc--C2C_Fuser/snapshots/909c76d71cfb946171aa2ab7912dd07c0ba2e995/qwen3_0.6b+qwen2.5_0.5b_Fuser/final
2025-12-20 10:44:40,270 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-12-20 10:44:40,274 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen3-0.6B/c1899de289a04d12100db370d81485cdf75e47ca/tokenizer_config.json HTTP/1.1" 200 0
2025-12-20 10:44:40,304 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "GET /api/models/Qwen/Qwen3-0.6B/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-12-20 10:44:40,679 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/config.json HTTP/1.1" 307 0
2025-12-20 10:44:40,684 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen3-0.6B/c1899de289a04d12100db370d81485cdf75e47ca/config.json HTTP/1.1" 200 0
2025-12-20 10:44:42,060 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/generation_config.json HTTP/1.1" 307 0
2025-12-20 10:44:42,065 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen3-0.6B/c1899de289a04d12100db370d81485cdf75e47ca/generation_config.json HTTP/1.1" 200 0
2025-12-20 10:44:42,091 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /Qwen/Qwen3-0.6B/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-12-20 10:44:42,120 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /Qwen/Qwen2.5-0.5B-Instruct/resolve/main/config.json HTTP/1.1" 307 0
2025-12-20 10:44:42,124 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen2.5-0.5B-Instruct/7ae557604adf67be50417f59c2c2f167def9a775/config.json HTTP/1.1" 200 0
2025-12-20 10:44:42,965 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /Qwen/Qwen2.5-0.5B-Instruct/resolve/main/generation_config.json HTTP/1.1" 307 0
2025-12-20 10:44:42,970 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /api/resolve-cache/models/Qwen/Qwen2.5-0.5B-Instruct/7ae557604adf67be50417f59c2c2f167def9a775/generation_config.json HTTP/1.1" 200 0
2025-12-20 10:44:42,999 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /Qwen/Qwen2.5-0.5B-Instruct/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-12-20 10:44:50,332 - script.playground.inference_example - INFO - Loading projectors...with element C2CProjector(
  (key_in): Linear(in_features=1152, out_features=1024, bias=True)
  (value_in): Linear(in_features=1152, out_features=1024, bias=True)
  (key_mlp1): RegularMLP(
    (blocks): ModuleList(
      (0): StandardFFNLayer(
        (norm): RMSNorm((1024,), eps=1e-06, elementwise_affine=True)
        (w1): Linear(in_features=1024, out_features=1024, bias=False)
        (w2): Linear(in_features=1024, out_features=1024, bias=False)
        (drop): Dropout(p=0.1, inplace=False)
        (act): GELU(approximate='none')
      )
    )
  )
  (value_mlp1): RegularMLP(
    (blocks): ModuleList(
      (0): StandardFFNLayer(
        (norm): RMSNorm((1024,), eps=1e-06, elementwise_affine=True)
        (w1): Linear(in_features=1024, out_features=1024, bias=False)
        (w2): Linear(in_features=1024, out_features=1024, bias=False)
        (drop): Dropout(p=0.1, inplace=False)
        (act): GELU(approximate='none')
      )
    )
  )
  (key_scalar_mlp2): RegularMLP(
    (blocks): ModuleList(
      (0): StandardFFNLayer(
        (norm): RMSNorm((1024,), eps=1e-06, elementwise_affine=True)
        (w1): Linear(in_features=1024, out_features=1024, bias=False)
        (w2): Linear(in_features=1024, out_features=1024, bias=False)
        (drop): Dropout(p=0.1, inplace=False)
        (act): GELU(approximate='none')
      )
    )
  )
  (value_scalar_mlp2): RegularMLP(
    (blocks): ModuleList(
      (0): StandardFFNLayer(
        (norm): RMSNorm((1024,), eps=1e-06, elementwise_affine=True)
        (w1): Linear(in_features=1024, out_features=1024, bias=False)
        (w2): Linear(in_features=1024, out_features=1024, bias=False)
        (drop): Dropout(p=0.1, inplace=False)
        (act): GELU(approximate='none')
      )
    )
  )
  (key_scalar_head): Linear(in_features=1024, out_features=8, bias=True)
  (value_scalar_head): Linear(in_features=1024, out_features=8, bias=True)
  (key_proj_mlp2): RegularMLP(
    (blocks): ModuleList(
      (0): StandardFFNLayer(
        (norm): RMSNorm((1024,), eps=1e-06, elementwise_affine=True)
        (w1): Linear(in_features=1024, out_features=1024, bias=False)
        (w2): Linear(in_features=1024, out_features=1024, bias=False)
        (drop): Dropout(p=0.1, inplace=False)
        (act): GELU(approximate='none')
      )
    )
  )
  (value_proj_mlp2): RegularMLP(
    (blocks): ModuleList(
      (0): StandardFFNLayer(
        (norm): RMSNorm((1024,), eps=1e-06, elementwise_affine=True)
        (w1): Linear(in_features=1024, out_features=1024, bias=False)
        (w2): Linear(in_features=1024, out_features=1024, bias=False)
        (drop): Dropout(p=0.1, inplace=False)
        (act): GELU(approximate='none')
      )
    )
  )
  (key_proj_out): Linear(in_features=1024, out_features=1024, bias=True)
  (value_proj_out): Linear(in_features=1024, out_features=1024, bias=True)
) and total count 28
2025-12-20 10:44:50,333 - script.playground.inference_example - INFO - Loading aggregators...[]
2025-12-20 10:44:50,371 - script.playground.inference_example - INFO - Rosetta model loaded successfully:RosettaModel(
  models=2,
    [0] Qwen3ForCausalLM (base)
    [1] Qwen2ForCausalLM
  projectors=28 (mappings=0),
  aggregators=0,
  fusion_mode='parallel',
  kv_cache: empty,
  device=cuda:0
)
2025-12-20 10:44:50,371 - rosetta.model.wrapper - INFO - Loaded projector config: {0: {1: {0: [[0, 0]], 1: [[0, 1]], 2: [[0, 2]], 3: [[0, 3]], 4: [[0, 4]], 5: [[1, 5]], 6: [[2, 6]], 7: [[3, 7]], 8: [[4, 8]], 9: [[5, 9]], 10: [[6, 10]], 11: [[7, 11]], 12: [[8, 12]], 13: [[9, 13]], 14: [[10, 14]], 15: [[11, 15]], 16: [[12, 16]], 17: [[13, 17]], 18: [[14, 18]], 19: [[15, 19]], 20: [[16, 20]], 21: [[17, 21]], 22: [[18, 22]], 23: [[19, 23]], 24: [[20, 24]], 25: [[21, 25]], 26: [[22, 26]], 27: [[23, 27]]}}}
2025-12-20 10:44:50,394 - rosetta.model.wrapper - DEBUG - Starting generation with max_new_tokens=256, do_sample=False, temperature=1.0
2025-12-20 10:44:50,394 - rosetta.model.wrapper - DEBUG - Starting prefill phase with prompt length=19
2025-12-20 10:44:50,397 - rosetta.model.wrapper - DEBUG - RosettaModel forward called, with kv_cache_index=[tensor([[[1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0],
         [1, 0]]], device='cuda:0'), tensor([[[-1,  0]]], device='cuda:0')]
2025-12-20 10:44:50,397 - rosetta.model.wrapper - DEBUG - RosettaModel forward: seqlen=19, num_sections=2
2025-12-20 10:44:50,397 - rosetta.model.wrapper - DEBUG - parsing section lengths: [18, 1]
2025-12-20 10:44:50,397 - rosetta.model.wrapper - DEBUG - computed section starts: [0, 18, 19]
2025-12-20 10:44:50,397 - rosetta.model.wrapper - DEBUG - Entering prefill phase, fuse kv cache accourding to kv_cache_index
2025-12-20 10:44:50,397 - rosetta.model.wrapper - DEBUG - Processing section 1/2
2025-12-20 10:44:50,397 - rosetta.model.wrapper - DEBUG - Prefill inputs: input_ids shape=torch.Size([1, 18]), attention_mask shape=torch.Size([1, 18]), position_ids shape=None, labels shape=None
2025-12-20 10:44:51,060 - rosetta.model.wrapper - DEBUG - Base model output obtained for section 1
2025-12-20 10:44:51,060 - rosetta.model.wrapper - DEBUG - Current KV Cache for base model - num_layers: 28, key_shape: torch.Size([1, 8, 18, 128]), value_shape: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,060 - rosetta.model.wrapper - DEBUG - if this is not the last section, process source models for kv-cache projection
2025-12-20 10:44:51,060 - rosetta.model.wrapper - DEBUG - Processing source model's attention mask for kv-cache projection
2025-12-20 10:44:51,141 - rosetta.model.wrapper - DEBUG - Section 1: sharer_mask=1
2025-12-20 10:44:51,141 - rosetta.model.wrapper - DEBUG - >0: Bitmask selecting sharers (1 (001)=sharer1, 2 (010)=sharer2, 3 (011)=both, 7 (111)=all three)
2025-12-20 10:44:51,141 - rosetta.model.wrapper - DEBUG - iterating over source models for projection
2025-12-20 10:44:51,142 - rosetta.model.wrapper - DEBUG - Processing source model in each target layer  for projection
2025-12-20 10:44:51,142 - rosetta.model.wrapper - DEBUG - Target layer 0 with projector entry: [[0, 0]]
2025-12-20 10:44:51,142 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,142 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,142 - rosetta.model.wrapper - DEBUG - Using source model layer 0 with projector 0
2025-12-20 10:44:51,161 - rosetta.model.wrapper - DEBUG - Target layer 1 with projector entry: [[0, 1]]
2025-12-20 10:44:51,161 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,161 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,161 - rosetta.model.wrapper - DEBUG - Using source model layer 0 with projector 1
2025-12-20 10:44:51,165 - rosetta.model.wrapper - DEBUG - Target layer 2 with projector entry: [[0, 2]]
2025-12-20 10:44:51,165 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,165 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,165 - rosetta.model.wrapper - DEBUG - Using source model layer 0 with projector 2
2025-12-20 10:44:51,169 - rosetta.model.wrapper - DEBUG - Target layer 3 with projector entry: [[0, 3]]
2025-12-20 10:44:51,169 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,169 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,169 - rosetta.model.wrapper - DEBUG - Using source model layer 0 with projector 3
2025-12-20 10:44:51,172 - rosetta.model.wrapper - DEBUG - Target layer 4 with projector entry: [[0, 4]]
2025-12-20 10:44:51,173 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,173 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,173 - rosetta.model.wrapper - DEBUG - Using source model layer 0 with projector 4
2025-12-20 10:44:51,176 - rosetta.model.wrapper - DEBUG - Target layer 5 with projector entry: [[1, 5]]
2025-12-20 10:44:51,176 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,177 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,177 - rosetta.model.wrapper - DEBUG - Using source model layer 1 with projector 5
2025-12-20 10:44:51,180 - rosetta.model.wrapper - DEBUG - Target layer 6 with projector entry: [[2, 6]]
2025-12-20 10:44:51,180 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,180 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,180 - rosetta.model.wrapper - DEBUG - Using source model layer 2 with projector 6
2025-12-20 10:44:51,184 - rosetta.model.wrapper - DEBUG - Target layer 7 with projector entry: [[3, 7]]
2025-12-20 10:44:51,184 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,184 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,184 - rosetta.model.wrapper - DEBUG - Using source model layer 3 with projector 7
2025-12-20 10:44:51,188 - rosetta.model.wrapper - DEBUG - Target layer 8 with projector entry: [[4, 8]]
2025-12-20 10:44:51,188 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,188 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,188 - rosetta.model.wrapper - DEBUG - Using source model layer 4 with projector 8
2025-12-20 10:44:51,192 - rosetta.model.wrapper - DEBUG - Target layer 9 with projector entry: [[5, 9]]
2025-12-20 10:44:51,192 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,192 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,192 - rosetta.model.wrapper - DEBUG - Using source model layer 5 with projector 9
2025-12-20 10:44:51,196 - rosetta.model.wrapper - DEBUG - Target layer 10 with projector entry: [[6, 10]]
2025-12-20 10:44:51,196 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,196 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,196 - rosetta.model.wrapper - DEBUG - Using source model layer 6 with projector 10
2025-12-20 10:44:51,200 - rosetta.model.wrapper - DEBUG - Target layer 11 with projector entry: [[7, 11]]
2025-12-20 10:44:51,200 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,200 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,200 - rosetta.model.wrapper - DEBUG - Using source model layer 7 with projector 11
2025-12-20 10:44:51,204 - rosetta.model.wrapper - DEBUG - Target layer 12 with projector entry: [[8, 12]]
2025-12-20 10:44:51,204 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,204 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,204 - rosetta.model.wrapper - DEBUG - Using source model layer 8 with projector 12
2025-12-20 10:44:51,208 - rosetta.model.wrapper - DEBUG - Target layer 13 with projector entry: [[9, 13]]
2025-12-20 10:44:51,208 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,208 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,208 - rosetta.model.wrapper - DEBUG - Using source model layer 9 with projector 13
2025-12-20 10:44:51,211 - rosetta.model.wrapper - DEBUG - Target layer 14 with projector entry: [[10, 14]]
2025-12-20 10:44:51,212 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,212 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,212 - rosetta.model.wrapper - DEBUG - Using source model layer 10 with projector 14
2025-12-20 10:44:51,215 - rosetta.model.wrapper - DEBUG - Target layer 15 with projector entry: [[11, 15]]
2025-12-20 10:44:51,215 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,216 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,216 - rosetta.model.wrapper - DEBUG - Using source model layer 11 with projector 15
2025-12-20 10:44:51,221 - rosetta.model.wrapper - DEBUG - Target layer 16 with projector entry: [[12, 16]]
2025-12-20 10:44:51,221 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,221 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,221 - rosetta.model.wrapper - DEBUG - Using source model layer 12 with projector 16
2025-12-20 10:44:51,225 - rosetta.model.wrapper - DEBUG - Target layer 17 with projector entry: [[13, 17]]
2025-12-20 10:44:51,225 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,225 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,225 - rosetta.model.wrapper - DEBUG - Using source model layer 13 with projector 17
2025-12-20 10:44:51,229 - rosetta.model.wrapper - DEBUG - Target layer 18 with projector entry: [[14, 18]]
2025-12-20 10:44:51,229 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,229 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,229 - rosetta.model.wrapper - DEBUG - Using source model layer 14 with projector 18
2025-12-20 10:44:51,233 - rosetta.model.wrapper - DEBUG - Target layer 19 with projector entry: [[15, 19]]
2025-12-20 10:44:51,233 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,233 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,233 - rosetta.model.wrapper - DEBUG - Using source model layer 15 with projector 19
2025-12-20 10:44:51,237 - rosetta.model.wrapper - DEBUG - Target layer 20 with projector entry: [[16, 20]]
2025-12-20 10:44:51,237 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,237 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,237 - rosetta.model.wrapper - DEBUG - Using source model layer 16 with projector 20
2025-12-20 10:44:51,241 - rosetta.model.wrapper - DEBUG - Target layer 21 with projector entry: [[17, 21]]
2025-12-20 10:44:51,241 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,241 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,241 - rosetta.model.wrapper - DEBUG - Using source model layer 17 with projector 21
2025-12-20 10:44:51,245 - rosetta.model.wrapper - DEBUG - Target layer 22 with projector entry: [[18, 22]]
2025-12-20 10:44:51,245 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,245 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,245 - rosetta.model.wrapper - DEBUG - Using source model layer 18 with projector 22
2025-12-20 10:44:51,249 - rosetta.model.wrapper - DEBUG - Target layer 23 with projector entry: [[19, 23]]
2025-12-20 10:44:51,249 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,249 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,249 - rosetta.model.wrapper - DEBUG - Using source model layer 19 with projector 23
2025-12-20 10:44:51,253 - rosetta.model.wrapper - DEBUG - Target layer 24 with projector entry: [[20, 24]]
2025-12-20 10:44:51,253 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,253 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,253 - rosetta.model.wrapper - DEBUG - Using source model layer 20 with projector 24
2025-12-20 10:44:51,256 - rosetta.model.wrapper - DEBUG - Target layer 25 with projector entry: [[21, 25]]
2025-12-20 10:44:51,256 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,257 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,257 - rosetta.model.wrapper - DEBUG - Using source model layer 21 with projector 25
2025-12-20 10:44:51,260 - rosetta.model.wrapper - DEBUG - Target layer 26 with projector entry: [[22, 26]]
2025-12-20 10:44:51,260 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,260 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,260 - rosetta.model.wrapper - DEBUG - Using source model layer 22 with projector 26
2025-12-20 10:44:51,264 - rosetta.model.wrapper - DEBUG - Target layer 27 with projector entry: [[23, 27]]
2025-12-20 10:44:51,264 - rosetta.model.wrapper - DEBUG - New base KV cache slice shapes - key: torch.Size([1, 8, 18, 128]), value: torch.Size([1, 8, 18, 128])
2025-12-20 10:44:51,264 - rosetta.model.wrapper - DEBUG - Start KV Cache Projection
2025-12-20 10:44:51,264 - rosetta.model.wrapper - DEBUG - Using source model layer 23 with projector 27
2025-12-20 10:44:51,270 - rosetta.model.wrapper - DEBUG - Processing section 2/2
2025-12-20 10:44:51,270 - rosetta.model.wrapper - DEBUG - Prefill inputs: input_ids shape=torch.Size([1, 1]), attention_mask shape=torch.Size([1, 19]), position_ids shape=None, labels shape=None
2025-12-20 10:44:51,326 - rosetta.model.wrapper - DEBUG - Base model output obtained for section 2
2025-12-20 10:44:51,326 - rosetta.model.wrapper - DEBUG - Current KV Cache for base model - num_layers: 28, key_shape: torch.Size([1, 8, 19, 128]), value_shape: torch.Size([1, 8, 19, 128])
2025-12-20 10:44:51,326 - rosetta.model.wrapper - DEBUG - Section 2: sharer_mask=-1
2025-12-20 10:44:51,327 - rosetta.model.wrapper - DEBUG - Prefill phase completed
2025-12-20 10:44:51,343 - rosetta.model.wrapper - DEBUG - RosettaModel forward called, with kv_cache_index=[tensor([[[-1,  0]]], device='cuda:0')]
2025-12-20 10:44:51,343 - rosetta.model.wrapper - DEBUG - RosettaModel forward: seqlen=1, num_sections=1
2025-12-20 10:44:51,343 - rosetta.model.wrapper - DEBUG - parsing section lengths: [1]
2025-12-20 10:44:51,343 - rosetta.model.wrapper - DEBUG - computed section starts: [0, 1]
2025-12-20 10:44:51,343 - rosetta.model.wrapper - DEBUG - Entering prefill phase, fuse kv cache accourding to kv_cache_index
2025-12-20 10:44:51,343 - rosetta.model.wrapper - DEBUG - Processing section 1/1
2025-12-20 10:44:51,343 - rosetta.model.wrapper - DEBUG - Prefill inputs: input_ids shape=torch.Size([1, 1]), attention_mask shape=torch.Size([1, 1]), position_ids shape=None, labels shape=None
2025-12-20 10:44:51,377 - rosetta.model.wrapper - DEBUG - Base model output obtained for section 1
2025-12-20 10:44:51,377 - rosetta.model.wrapper - DEBUG - Current KV Cache for base model - num_layers: 28, key_shape: torch.Size([1, 8, 20, 128]), value_shape: torch.Size([1, 8, 20, 128])
2025-12-20 10:44:51,377 - rosetta.model.wrapper - DEBUG - Section 1: sharer_mask=-1
2025-12-20 10:44:51,378 - rosetta.model.wrapper - DEBUG - RosettaModel forward called, with kv_cache_index=[tensor([[[-1,  0]]], device='cuda:0')]
2025-12-20 10:44:51,378 - rosetta.model.wrapper - DEBUG - RosettaModel forward: seqlen=1, num_sections=1
2025-12-20 10:44:51,378 - rosetta.model.wrapper - DEBUG - parsing section lengths: [1]
2025-12-20 10:44:51,378 - rosetta.model.wrapper - DEBUG - computed section starts: [0, 1]
2025-12-20 10:44:51,378 - rosetta.model.wrapper - DEBUG - Entering prefill phase, fuse kv cache accourding to kv_cache_index
2025-12-20 10:44:51,378 - rosetta.model.wrapper - DEBUG - Processing section 1/1
2025-12-20 10:44:51,378 - rosetta.model.wrapper - DEBUG - Prefill inputs: input_ids shape=torch.Size([1, 1]), attention_mask shape=torch.Size([1, 1]), position_ids shape=None, labels shape=None
2025-12-20 10:44:51,412 - rosetta.model.wrapper - DEBUG - Base model output obtained for section 1
2025-12-20 10:44:51,412 - rosetta.model.wrapper - DEBUG - Current KV Cache for base model - num_layers: 28, key_shape: torch.Size([1, 8, 21, 128]), value_shape: torch.Size([1, 8, 21, 128])
2025-12-20 10:44:51,413 - rosetta.model.wrapper - DEBUG - Section 1: sharer_mask=-1
2025-12-20 10:44:51,413 - rosetta.model.wrapper - DEBUG - RosettaModel forward called, with kv_cache_index=[tensor([[[-1,  0]]], device='cuda:0')]
2025-12-20 10:44:51,413 - rosetta.model.wrapper - DEBUG - RosettaModel forward: seqlen=1, num_sections=1
2025-12-20 10:44:51,413 - rosetta.model.wrapper - DEBUG - parsing section lengths: [1]
2025-12-20 10:44:51,413 - rosetta.model.wrapper - DEBUG - computed section starts: [0, 1]
2025-12-20 10:44:51,413 - rosetta.model.wrapper - DEBUG - Entering prefill phase, fuse kv cache accourding to kv_cache_index
2025-12-20 10:44:51,413 - rosetta.model.wrapper - DEBUG - Processing section 1/1
2025-12-20 10:44:51,413 - rosetta.model.wrapper - DEBUG - Prefill inputs: input_ids shape=torch.Size([1, 1]), attention_mask shape=torch.Size([1, 1]), position_ids shape=None, labels shape=None
2025-12-20 10:44:51,447 - rosetta.model.wrapper - DEBUG - Base model output obtained for section 1
2025-12-20 10:44:51,447 - rosetta.model.wrapper - DEBUG - Current KV Cache for base model - num_layers: 28, key_shape: torch.Size([1, 8, 22, 128]), value_shape: torch.Size([1, 8, 22, 128])
2025-12-20 10:44:51,448 - rosetta.model.wrapper - DEBUG - Section 1: sharer_mask=-1
2025-12-20 10:44:51,448 - rosetta.model.wrapper - DEBUG - RosettaModel forward called, with kv_cache_index=[tensor([[[-1,  0]]], device='cuda:0')]
2025-12-20 10:44:51,448 - rosetta.model.wrapper - DEBUG - RosettaModel forward: seqlen=1, num_sections=1
2025-12-20 10:44:51,448 - rosetta.model.wrapper - DEBUG - parsing section lengths: [1]
2025-12-20 10:44:51,448 - rosetta.model.wrapper - DEBUG - computed section starts: [0, 1]
2025-12-20 10:44:51,448 - rosetta.model.wrapper - DEBUG - Entering prefill phase, fuse kv cache accourding to kv_cache_index
2025-12-20 10:44:51,448 - rosetta.model.wrapper - DEBUG - Processing section 1/1
2025-12-20 10:44:51,448 - rosetta.model.wrapper - DEBUG - Prefill inputs: input_ids shape=torch.Size([1, 1]), attention_mask shape=torch.Size([1, 1]), position_ids shape=None, labels shape=None
2025-12-20 10:44:51,482 - rosetta.model.wrapper - DEBUG - Base model output obtained for section 1
2025-12-20 10:44:51,482 - rosetta.model.wrapper - DEBUG - Current KV Cache for base model - num_layers: 28, key_shape: torch.Size([1, 8, 23, 128]), value_shape: torch.Size([1, 8, 23, 128])
2025-12-20 10:44:51,483 - rosetta.model.wrapper - DEBUG - Section 1: sharer_mask=-1
2025-12-20 10:44:51,483 - rosetta.model.wrapper - DEBUG - RosettaModel forward called, with kv_cache_index=[tensor([[[-1,  0]]], device='cuda:0')]
2025-12-20 10:44:51,483 - rosetta.model.wrapper - DEBUG - RosettaModel forward: seqlen=1, num_sections=1
2025-12-20 10:44:51,483 - rosetta.model.wrapper - DEBUG - parsing section lengths: [1]
2025-12-20 10:44:51,483 - rosetta.model.wrapper - DEBUG - computed section starts: [0, 1]
2025-12-20 10:44:51,483 - rosetta.model.wrapper - DEBUG - Entering prefill phase, fuse kv cache accourding to kv_cache_index
2025-12-20 10:44:51,483 - rosetta.model.wrapper - DEBUG - Processing section 1/1
2025-12-20 10:44:51,483 - rosetta.model.wrapper - DEBUG - Prefill inputs: input_ids shape=torch.Size([1, 1]), attention_mask shape=torch.Size([1, 1]), position_ids shape=None, labels shape=None
2025-12-20 10:44:51,517 - rosetta.model.wrapper - DEBUG - Base model output obtained for section 1
2025-12-20 10:44:51,517 - rosetta.model.wrapper - DEBUG - Current KV Cache for base model - num_layers: 28, key_shape: torch.Size([1, 8, 24, 128]), value_shape: torch.Size([1, 8, 24, 128])
2025-12-20 10:44:51,517 - rosetta.model.wrapper - DEBUG - Section 1: sharer_mask=-1
2025-12-20 10:44:51,518 - rosetta.model.wrapper - DEBUG - RosettaModel forward called, with kv_cache_index=[tensor([[[-1,  0]]], device='cuda:0')]
2025-12-20 10:44:51,518 - rosetta.model.wrapper - DEBUG - RosettaModel forward: seqlen=1, num_sections=1
2025-12-20 10:44:51,518 - rosetta.model.wrapper - DEBUG - parsing section lengths: [1]
2025-12-20 10:44:51,518 - rosetta.model.wrapper - DEBUG - computed section starts: [0, 1]
2025-12-20 10:44:51,518 - rosetta.model.wrapper - DEBUG - Entering prefill phase, fuse kv cache accourding to kv_cache_index
2025-12-20 10:44:51,518 - rosetta.model.wrapper - DEBUG - Processing section 1/1
2025-12-20 10:44:51,518 - rosetta.model.wrapper - DEBUG - Prefill inputs: input_ids shape=torch.Size([1, 1]), attention_mask shape=torch.Size([1, 1]), position_ids shape=None, labels shape=None
2025-12-20 10:44:51,552 - rosetta.model.wrapper - DEBUG - Base model output obtained for section 1
2025-12-20 10:44:51,552 - rosetta.model.wrapper - DEBUG - Current KV Cache for base model - num_layers: 28, key_shape: torch.Size([1, 8, 25, 128]), value_shape: torch.Size([1, 8, 25, 128])
2025-12-20 10:44:51,552 - rosetta.model.wrapper - DEBUG - Section 1: sharer_mask=-1
2025-12-20 10:44:51,553 - rosetta.model.wrapper - DEBUG - RosettaModel forward called, with kv_cache_index=[tensor([[[-1,  0]]], device='cuda:0')]
2025-12-20 10:44:51,553 - rosetta.model.wrapper - DEBUG - RosettaModel forward: seqlen=1, num_sections=1
2025-12-20 10:44:51,553 - rosetta.model.wrapper - DEBUG - parsing section lengths: [1]
2025-12-20 10:44:51,553 - rosetta.model.wrapper - DEBUG - computed section starts: [0, 1]
2025-12-20 10:44:51,553 - rosetta.model.wrapper - DEBUG - Entering prefill phase, fuse kv cache accourding to kv_cache_index
2025-12-20 10:44:51,553 - rosetta.model.wrapper - DEBUG - Processing section 1/1
2025-12-20 10:44:51,553 - rosetta.model.wrapper - DEBUG - Prefill inputs: input_ids shape=torch.Size([1, 1]), attention_mask shape=torch.Size([1, 1]), position_ids shape=None, labels shape=None
2025-12-20 10:44:51,588 - rosetta.model.wrapper - DEBUG - Base model output obtained for section 1
2025-12-20 10:44:51,589 - rosetta.model.wrapper - DEBUG - Current KV Cache for base model - num_layers: 28, key_shape: torch.Size([1, 8, 26, 128]), value_shape: torch.Size([1, 8, 26, 128])
2025-12-20 10:44:51,589 - rosetta.model.wrapper - DEBUG - Section 1: sharer_mask=-1
2025-12-20 10:44:51,589 - rosetta.model.wrapper - DEBUG - RosettaModel forward called, with kv_cache_index=[tensor([[[-1,  0]]], device='cuda:0')]
2025-12-20 10:44:51,589 - rosetta.model.wrapper - DEBUG - RosettaModel forward: seqlen=1, num_sections=1
2025-12-20 10:44:51,589 - rosetta.model.wrapper - DEBUG - parsing section lengths: [1]
2025-12-20 10:44:51,590 - rosetta.model.wrapper - DEBUG - computed section starts: [0, 1]
2025-12-20 10:44:51,590 - rosetta.model.wrapper - DEBUG - Entering prefill phase, fuse kv cache accourding to kv_cache_index
2025-12-20 10:44:51,590 - rosetta.model.wrapper - DEBUG - Processing section 1/1
2025-12-20 10:44:51,590 - rosetta.model.wrapper - DEBUG - Prefill inputs: input_ids shape=torch.Size([1, 1]), attention_mask shape=torch.Size([1, 1]), position_ids shape=None, labels shape=None
2025-12-20 10:44:51,623 - rosetta.model.wrapper - DEBUG - Base model output obtained for section 1
2025-12-20 10:44:51,623 - rosetta.model.wrapper - DEBUG - Current KV Cache for base model - num_layers: 28, key_shape: torch.Size([1, 8, 27, 128]), value_shape: torch.Size([1, 8, 27, 128])
2025-12-20 10:44:51,624 - rosetta.model.wrapper - DEBUG - Section 1: sharer_mask=-1
2025-12-20 10:44:51,624 - rosetta.model.wrapper - DEBUG - RosettaModel forward called, with kv_cache_index=[tensor([[[-1,  0]]], device='cuda:0')]
2025-12-20 10:44:51,624 - rosetta.model.wrapper - DEBUG - RosettaModel forward: seqlen=1, num_sections=1
2025-12-20 10:44:51,624 - rosetta.model.wrapper - DEBUG - parsing section lengths: [1]
2025-12-20 10:44:51,624 - rosetta.model.wrapper - DEBUG - computed section starts: [0, 1]
2025-12-20 10:44:51,624 - rosetta.model.wrapper - DEBUG - Entering prefill phase, fuse kv cache accourding to kv_cache_index
2025-12-20 10:44:51,624 - rosetta.model.wrapper - DEBUG - Processing section 1/1
2025-12-20 10:44:51,625 - rosetta.model.wrapper - DEBUG - Prefill inputs: input_ids shape=torch.Size([1, 1]), attention_mask shape=torch.Size([1, 1]), position_ids shape=None, labels shape=None
2025-12-20 10:44:51,658 - rosetta.model.wrapper - DEBUG - Base model output obtained for section 1
2025-12-20 10:44:51,658 - rosetta.model.wrapper - DEBUG - Current KV Cache for base model - num_layers: 28, key_shape: torch.Size([1, 8, 28, 128]), value_shape: torch.Size([1, 8, 28, 128])
2025-12-20 10:44:51,659 - rosetta.model.wrapper - DEBUG - Section 1: sharer_mask=-1
2025-12-20 10:44:51,659 - rosetta.model.wrapper - DEBUG - Generation completed: generated 10 tokens
Model Qwen/Qwen3-0.6B already has a chat template.
C2C output text: Hello! How can I assist you today?
